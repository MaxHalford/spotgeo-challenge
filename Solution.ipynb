{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've already determined which pixels are \"interesting\" in the [previous notebook](Interesting.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>r</th>\n",
       "      <th>c</th>\n",
       "      <th>area</th>\n",
       "      <th>eccentricity</th>\n",
       "      <th>solidity</th>\n",
       "      <th>is_satellite</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>part</th>\n",
       "      <th>sequence</th>\n",
       "      <th>frame</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">test</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">1</th>\n",
       "      <th>1</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>334.000000</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.432836</td>\n",
       "      <td>339.350746</td>\n",
       "      <td>134</td>\n",
       "      <td>0.983181</td>\n",
       "      <td>0.853503</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.727273</td>\n",
       "      <td>264.642857</td>\n",
       "      <td>154</td>\n",
       "      <td>0.978166</td>\n",
       "      <td>0.865169</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.000000</td>\n",
       "      <td>321.000000</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18.993590</td>\n",
       "      <td>40.365385</td>\n",
       "      <td>156</td>\n",
       "      <td>0.975910</td>\n",
       "      <td>0.901734</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             r           c  area  eccentricity  solidity  \\\n",
       "part sequence frame                                                        \n",
       "test 1        1       2.000000  334.000000     5      0.000000  1.000000   \n",
       "              1       7.432836  339.350746   134      0.983181  0.853503   \n",
       "              1      10.727273  264.642857   154      0.978166  0.865169   \n",
       "              1       6.000000  321.000000     5      0.000000  1.000000   \n",
       "              1      18.993590   40.365385   156      0.975910  0.901734   \n",
       "\n",
       "                    is_satellite  \n",
       "part sequence frame               \n",
       "test 1        1             None  \n",
       "              1             None  \n",
       "              1             None  \n",
       "              1             None  \n",
       "              1             None  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "interesting = pd.read_pickle('data/interesting.pkl')\n",
    "interesting.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'8,349,960'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f'{len(interesting):,}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "def region(img: np.ndarray, r: int, c: int, w: int):\n",
    "    \"\"\"Returns the square of length width with (x, y) being at the center.\"\"\"\n",
    "    return img[\n",
    "        max(r - w, 0) : min(r + w + 1, img.shape[0]),\n",
    "        max(c - w, 0) : min(c + w + 1, img.shape[1])\n",
    "    ]\n",
    "\n",
    "def extract_features(img, r, c):\n",
    "    r3x3 = region(img, r, c, 3).ravel()\n",
    "    r5x5 = region(img, r, c, 5).ravel()\n",
    "    r7x7 = region(img, r, c, 7).ravel()\n",
    "    val = img[r, c]\n",
    "    return {\n",
    "        'pixel_value': val,\n",
    "        '3x3_std': r3x3.std(),\n",
    "        '3x3_min': val - r3x3.min(),\n",
    "        '3x3_max': val - r3x3.max(),\n",
    "        '5x5_std': r5x5.std(),\n",
    "        '5x5_entropy': stats.entropy(r5x5),\n",
    "        '5x5_min': val - r5x5.min(),\n",
    "        '5x5_max': val - r5x5.max(),\n",
    "        '7x7_std': r7x7.std(),\n",
    "        '7x7_entropy': stats.entropy(r7x7),\n",
    "        '7x7_kurtosis': stats.kurtosis(r7x7),\n",
    "        '7x7_skew': stats.skew(r7x7)\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract features for each interesting region."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32000/32000 [1:33:12<00:00,  5.72it/s]  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>is_satellite</th>\n",
       "      <th>area</th>\n",
       "      <th>eccentricity</th>\n",
       "      <th>solidity</th>\n",
       "      <th>pixel_value</th>\n",
       "      <th>3x3_std</th>\n",
       "      <th>3x3_min</th>\n",
       "      <th>3x3_max</th>\n",
       "      <th>5x5_std</th>\n",
       "      <th>5x5_entropy</th>\n",
       "      <th>5x5_min</th>\n",
       "      <th>5x5_max</th>\n",
       "      <th>7x7_std</th>\n",
       "      <th>7x7_entropy</th>\n",
       "      <th>7x7_kurtosis</th>\n",
       "      <th>7x7_skew</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>part</th>\n",
       "      <th>sequence</th>\n",
       "      <th>frame</th>\n",
       "      <th>r</th>\n",
       "      <th>c</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">test</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">1</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">1</th>\n",
       "      <th>2</th>\n",
       "      <th>334</th>\n",
       "      <td>None</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>51.0</td>\n",
       "      <td>2.742543</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.626940</td>\n",
       "      <td>4.472527</td>\n",
       "      <td>12.0</td>\n",
       "      <td>-16.0</td>\n",
       "      <td>7.047171</td>\n",
       "      <td>5.000321</td>\n",
       "      <td>1.346526</td>\n",
       "      <td>1.517550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <th>339</th>\n",
       "      <td>None</td>\n",
       "      <td>134</td>\n",
       "      <td>0.983181</td>\n",
       "      <td>0.853503</td>\n",
       "      <td>66.0</td>\n",
       "      <td>8.833364</td>\n",
       "      <td>26.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>7.947879</td>\n",
       "      <td>4.783086</td>\n",
       "      <td>27.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>7.186401</td>\n",
       "      <td>5.405223</td>\n",
       "      <td>1.016366</td>\n",
       "      <td>1.443022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <th>264</th>\n",
       "      <td>None</td>\n",
       "      <td>154</td>\n",
       "      <td>0.978166</td>\n",
       "      <td>0.865169</td>\n",
       "      <td>94.0</td>\n",
       "      <td>18.666742</td>\n",
       "      <td>54.0</td>\n",
       "      <td>-7.0</td>\n",
       "      <td>17.242287</td>\n",
       "      <td>4.750768</td>\n",
       "      <td>55.0</td>\n",
       "      <td>-7.0</td>\n",
       "      <td>15.642723</td>\n",
       "      <td>5.376112</td>\n",
       "      <td>1.676764</td>\n",
       "      <td>1.720753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <th>321</th>\n",
       "      <td>None</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>51.0</td>\n",
       "      <td>2.940476</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.627891</td>\n",
       "      <td>4.794033</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.687508</td>\n",
       "      <td>5.345273</td>\n",
       "      <td>0.914122</td>\n",
       "      <td>0.866791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <th>40</th>\n",
       "      <td>None</td>\n",
       "      <td>156</td>\n",
       "      <td>0.975910</td>\n",
       "      <td>0.901734</td>\n",
       "      <td>96.0</td>\n",
       "      <td>18.950119</td>\n",
       "      <td>55.0</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>17.164404</td>\n",
       "      <td>4.751998</td>\n",
       "      <td>59.0</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>15.657648</td>\n",
       "      <td>5.376683</td>\n",
       "      <td>1.718475</td>\n",
       "      <td>1.725620</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           is_satellite  area  eccentricity  solidity  \\\n",
       "part sequence frame r  c                                                \n",
       "test 1        1     2  334         None     5      0.000000  1.000000   \n",
       "                    7  339         None   134      0.983181  0.853503   \n",
       "                    10 264         None   154      0.978166  0.865169   \n",
       "                    6  321         None     5      0.000000  1.000000   \n",
       "                    18 40          None   156      0.975910  0.901734   \n",
       "\n",
       "                            pixel_value    3x3_std  3x3_min  3x3_max  \\\n",
       "part sequence frame r  c                                               \n",
       "test 1        1     2  334         51.0   2.742543     12.0      0.0   \n",
       "                    7  339         66.0   8.833364     26.0     -2.0   \n",
       "                    10 264         94.0  18.666742     54.0     -7.0   \n",
       "                    6  321         51.0   2.940476     11.0      0.0   \n",
       "                    18 40          96.0  18.950119     55.0     -3.0   \n",
       "\n",
       "                              5x5_std  5x5_entropy  5x5_min  5x5_max  \\\n",
       "part sequence frame r  c                                               \n",
       "test 1        1     2  334   4.626940     4.472527     12.0    -16.0   \n",
       "                    7  339   7.947879     4.783086     27.0     -2.0   \n",
       "                    10 264  17.242287     4.750768     55.0     -7.0   \n",
       "                    6  321   2.627891     4.794033     12.0      0.0   \n",
       "                    18 40   17.164404     4.751998     59.0     -3.0   \n",
       "\n",
       "                              7x7_std  7x7_entropy  7x7_kurtosis  7x7_skew  \n",
       "part sequence frame r  c                                                    \n",
       "test 1        1     2  334   7.047171     5.000321      1.346526  1.517550  \n",
       "                    7  339   7.186401     5.405223      1.016366  1.443022  \n",
       "                    10 264  15.642723     5.376112      1.676764  1.720753  \n",
       "                    6  321   2.687508     5.345273      0.914122  0.866791  \n",
       "                    18 40   15.657648     5.376683      1.718475  1.725620  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import tqdm\n",
    "\n",
    "samples = {}\n",
    "\n",
    "# There should be 32000 frames (5 * 1280 + 5 * 5120)\n",
    "for (part, sequence, frame), locations in tqdm.tqdm(interesting.groupby(['part', 'sequence', 'frame']), position=0):\n",
    "\n",
    "#for (sequence, frame), locations in tqdm.tqdm(interesting.loc['train'].groupby(['sequence', 'frame']), position=0): \n",
    "#    part = 'train'\n",
    "    \n",
    "    img = np.asarray(Image.open(f'data/spotGEO/{part}/{sequence}/{frame}.png')).astype(np.float32)\n",
    "    \n",
    "    for _, location in locations.iterrows():\n",
    "    \n",
    "        r = int(location['r'])\n",
    "        c = int(location['c'])\n",
    "\n",
    "        samples[part, sequence, frame, r, c] = {\n",
    "            'is_satellite': location['is_satellite'],\n",
    "            'area': location['area'],\n",
    "            'eccentricity': location['eccentricity'],\n",
    "            'solidity':  location['solidity'],\n",
    "            **extract_features(img, r=r, c=c)\n",
    "        }\n",
    "        \n",
    "samples = pd.DataFrame.from_dict(samples, orient='index')\n",
    "samples.index.names = ['part', 'sequence', 'frame', 'r', 'c']\n",
    "samples.to_pickle('data/samples.pkl')\n",
    "samples.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning phase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split into train and test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import utils\n",
    "\n",
    "X_train = samples.loc['train'].copy()\n",
    "y_train = X_train.pop('is_satellite').astype(bool)\n",
    "X_train, y_train = utils.shuffle(X_train, y_train, random_state=42)\n",
    "\n",
    "try:\n",
    "    X_test = samples.loc['test'].drop(columns='is_satellite')\n",
    "except KeyError:\n",
    "    X_test = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do the LGBM CV dance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mInit signature:\u001b[0m\n",
       "\u001b[0mlightgbm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLGBMClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mboosting_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'gbdt'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mnum_leaves\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m31\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mmax_depth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mn_estimators\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0msubsample_for_bin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mobjective\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mmin_split_gain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mmin_child_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.001\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mmin_child_samples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0msubsample\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0msubsample_freq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mcolsample_bytree\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mreg_alpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mreg_lambda\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0msilent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mimportance_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'split'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m      LightGBM classifier.\n",
       "\u001b[0;31mInit docstring:\u001b[0m\n",
       "Construct a gradient boosting model.\n",
       "\n",
       "Parameters\n",
       "----------\n",
       "boosting_type : string, optional (default='gbdt')\n",
       "    'gbdt', traditional Gradient Boosting Decision Tree.\n",
       "    'dart', Dropouts meet Multiple Additive Regression Trees.\n",
       "    'goss', Gradient-based One-Side Sampling.\n",
       "    'rf', Random Forest.\n",
       "num_leaves : int, optional (default=31)\n",
       "    Maximum tree leaves for base learners.\n",
       "max_depth : int, optional (default=-1)\n",
       "    Maximum tree depth for base learners, <=0 means no limit.\n",
       "learning_rate : float, optional (default=0.1)\n",
       "    Boosting learning rate.\n",
       "    You can use ``callbacks`` parameter of ``fit`` method to shrink/adapt learning rate\n",
       "    in training using ``reset_parameter`` callback.\n",
       "    Note, that this will ignore the ``learning_rate`` argument in training.\n",
       "n_estimators : int, optional (default=100)\n",
       "    Number of boosted trees to fit.\n",
       "subsample_for_bin : int, optional (default=200000)\n",
       "    Number of samples for constructing bins.\n",
       "objective : string, callable or None, optional (default=None)\n",
       "    Specify the learning task and the corresponding learning objective or\n",
       "    a custom objective function to be used (see note below).\n",
       "    Default: 'regression' for LGBMRegressor, 'binary' or 'multiclass' for LGBMClassifier, 'lambdarank' for LGBMRanker.\n",
       "class_weight : dict, 'balanced' or None, optional (default=None)\n",
       "    Weights associated with classes in the form ``{class_label: weight}``.\n",
       "    Use this parameter only for multi-class classification task;\n",
       "    for binary classification task you may use ``is_unbalance`` or ``scale_pos_weight`` parameters.\n",
       "    Note, that the usage of all these parameters will result in poor estimates of the individual class probabilities.\n",
       "    You may want to consider performing probability calibration\n",
       "    (https://scikit-learn.org/stable/modules/calibration.html) of your model.\n",
       "    The 'balanced' mode uses the values of y to automatically adjust weights\n",
       "    inversely proportional to class frequencies in the input data as ``n_samples / (n_classes * np.bincount(y))``.\n",
       "    If None, all classes are supposed to have weight one.\n",
       "    Note, that these weights will be multiplied with ``sample_weight`` (passed through the ``fit`` method)\n",
       "    if ``sample_weight`` is specified.\n",
       "min_split_gain : float, optional (default=0.)\n",
       "    Minimum loss reduction required to make a further partition on a leaf node of the tree.\n",
       "min_child_weight : float, optional (default=1e-3)\n",
       "    Minimum sum of instance weight (hessian) needed in a child (leaf).\n",
       "min_child_samples : int, optional (default=20)\n",
       "    Minimum number of data needed in a child (leaf).\n",
       "subsample : float, optional (default=1.)\n",
       "    Subsample ratio of the training instance.\n",
       "subsample_freq : int, optional (default=0)\n",
       "    Frequence of subsample, <=0 means no enable.\n",
       "colsample_bytree : float, optional (default=1.)\n",
       "    Subsample ratio of columns when constructing each tree.\n",
       "reg_alpha : float, optional (default=0.)\n",
       "    L1 regularization term on weights.\n",
       "reg_lambda : float, optional (default=0.)\n",
       "    L2 regularization term on weights.\n",
       "random_state : int or None, optional (default=None)\n",
       "    Random number seed.\n",
       "    If None, default seeds in C++ code will be used.\n",
       "n_jobs : int, optional (default=-1)\n",
       "    Number of parallel threads.\n",
       "silent : bool, optional (default=True)\n",
       "    Whether to print messages while running boosting.\n",
       "importance_type : string, optional (default='split')\n",
       "    The type of feature importance to be filled into ``feature_importances_``.\n",
       "    If 'split', result contains numbers of times the feature is used in a model.\n",
       "    If 'gain', result contains total gains of splits which use the feature.\n",
       "**kwargs\n",
       "    Other parameters for the model.\n",
       "    Check http://lightgbm.readthedocs.io/en/latest/Parameters.html for more parameters.\n",
       "\n",
       "    .. warning::\n",
       "\n",
       "        \\*\\*kwargs is not supported in sklearn, it may cause unexpected issues.\n",
       "\n",
       "Attributes\n",
       "----------\n",
       "n_features_ : int\n",
       "    The number of features of fitted model.\n",
       "classes_ : array of shape = [n_classes]\n",
       "    The class label array (only for classification problem).\n",
       "n_classes_ : int\n",
       "    The number of classes (only for classification problem).\n",
       "best_score_ : dict or None\n",
       "    The best score of fitted model.\n",
       "best_iteration_ : int or None\n",
       "    The best iteration of fitted model if ``early_stopping_rounds`` has been specified.\n",
       "objective_ : string or callable\n",
       "    The concrete objective used while fitting this model.\n",
       "booster_ : Booster\n",
       "    The underlying Booster of this model.\n",
       "evals_result_ : dict or None\n",
       "    The evaluation results if ``early_stopping_rounds`` has been specified.\n",
       "feature_importances_ : array of shape = [n_features]\n",
       "    The feature importances (the higher, the more important the feature).\n",
       "\n",
       "Note\n",
       "----\n",
       "A custom objective function can be provided for the ``objective`` parameter.\n",
       "In this case, it should have the signature\n",
       "``objective(y_true, y_pred) -> grad, hess`` or\n",
       "``objective(y_true, y_pred, group) -> grad, hess``:\n",
       "\n",
       "    y_true : array-like of shape = [n_samples]\n",
       "        The target values.\n",
       "    y_pred : array-like of shape = [n_samples] or shape = [n_samples * n_classes] (for multi-class task)\n",
       "        The predicted values.\n",
       "    group : array-like\n",
       "        Group/query data, used for ranking task.\n",
       "    grad : array-like of shape = [n_samples] or shape = [n_samples * n_classes] (for multi-class task)\n",
       "        The value of the first order derivative (gradient) for each sample point.\n",
       "    hess : array-like of shape = [n_samples] or shape = [n_samples * n_classes] (for multi-class task)\n",
       "        The value of the second order derivative (Hessian) for each sample point.\n",
       "\n",
       "For multi-class task, the y_pred is group by class_id first, then group by row_id.\n",
       "If you want to get i-th row y_pred in j-th class, the access way is y_pred[j * num_data + i]\n",
       "and you should group grad and hess in this way as well.\n",
       "\u001b[0;31mFile:\u001b[0m           ~/opt/anaconda3/lib/python3.7/site-packages/lightgbm/sklearn.py\n",
       "\u001b[0;31mType:\u001b[0m           type\n",
       "\u001b[0;31mSubclasses:\u001b[0m     \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "?lightgbm.LGBMClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 20 rounds\n",
      "[100]\tfit's binary_logloss: 0.010353\tval's binary_logloss: 0.0111353\n",
      "[200]\tfit's binary_logloss: 0.00797899\tval's binary_logloss: 0.00920705\n",
      "[300]\tfit's binary_logloss: 0.00679675\tval's binary_logloss: 0.00850492\n",
      "[400]\tfit's binary_logloss: 0.00611734\tval's binary_logloss: 0.00817978\n",
      "[500]\tfit's binary_logloss: 0.00559571\tval's binary_logloss: 0.00797129\n",
      "[600]\tfit's binary_logloss: 0.00522142\tval's binary_logloss: 0.00783527\n",
      "[700]\tfit's binary_logloss: 0.0049254\tval's binary_logloss: 0.00774381\n",
      "[800]\tfit's binary_logloss: 0.00468476\tval's binary_logloss: 0.00768711\n",
      "[900]\tfit's binary_logloss: 0.00446799\tval's binary_logloss: 0.00764279\n",
      "[1000]\tfit's binary_logloss: 0.00426088\tval's binary_logloss: 0.00759326\n",
      "[1100]\tfit's binary_logloss: 0.00406992\tval's binary_logloss: 0.00755357\n",
      "[1200]\tfit's binary_logloss: 0.0038895\tval's binary_logloss: 0.00751615\n",
      "[1300]\tfit's binary_logloss: 0.00372246\tval's binary_logloss: 0.00748116\n",
      "[1400]\tfit's binary_logloss: 0.00357006\tval's binary_logloss: 0.00745501\n",
      "[1500]\tfit's binary_logloss: 0.00342193\tval's binary_logloss: 0.00742907\n",
      "[1600]\tfit's binary_logloss: 0.00328721\tval's binary_logloss: 0.00740811\n",
      "[1700]\tfit's binary_logloss: 0.00316495\tval's binary_logloss: 0.00738999\n",
      "[1800]\tfit's binary_logloss: 0.00304967\tval's binary_logloss: 0.00737349\n",
      "[1900]\tfit's binary_logloss: 0.0029408\tval's binary_logloss: 0.00736096\n",
      "[2000]\tfit's binary_logloss: 0.00283049\tval's binary_logloss: 0.00734608\n",
      "[2100]\tfit's binary_logloss: 0.00273333\tval's binary_logloss: 0.00733782\n",
      "[2200]\tfit's binary_logloss: 0.00263455\tval's binary_logloss: 0.00732594\n",
      "[2300]\tfit's binary_logloss: 0.0025415\tval's binary_logloss: 0.00731253\n",
      "[2400]\tfit's binary_logloss: 0.00245347\tval's binary_logloss: 0.00730633\n",
      "[2500]\tfit's binary_logloss: 0.00237578\tval's binary_logloss: 0.00729924\n",
      "[2600]\tfit's binary_logloss: 0.00229942\tval's binary_logloss: 0.00729519\n",
      "Early stopping, best iteration is:\n",
      "[2625]\tfit's binary_logloss: 0.00227883\tval's binary_logloss: 0.00729266\n",
      "\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[100]\tfit's binary_logloss: 0.0102328\tval's binary_logloss: 0.0115631\n",
      "[200]\tfit's binary_logloss: 0.00781354\tval's binary_logloss: 0.00957931\n",
      "[300]\tfit's binary_logloss: 0.00666811\tval's binary_logloss: 0.00883948\n",
      "[400]\tfit's binary_logloss: 0.00599332\tval's binary_logloss: 0.00846496\n",
      "[500]\tfit's binary_logloss: 0.00546985\tval's binary_logloss: 0.00824668\n",
      "[600]\tfit's binary_logloss: 0.00509507\tval's binary_logloss: 0.00810377\n",
      "[700]\tfit's binary_logloss: 0.00480293\tval's binary_logloss: 0.00801524\n",
      "[800]\tfit's binary_logloss: 0.00457297\tval's binary_logloss: 0.00794744\n",
      "[900]\tfit's binary_logloss: 0.00436301\tval's binary_logloss: 0.00789254\n",
      "[1000]\tfit's binary_logloss: 0.00416667\tval's binary_logloss: 0.00784726\n",
      "[1100]\tfit's binary_logloss: 0.00398666\tval's binary_logloss: 0.00780218\n",
      "[1200]\tfit's binary_logloss: 0.00381946\tval's binary_logloss: 0.00776732\n",
      "[1300]\tfit's binary_logloss: 0.00365922\tval's binary_logloss: 0.00773273\n",
      "[1400]\tfit's binary_logloss: 0.00350364\tval's binary_logloss: 0.00770182\n",
      "[1500]\tfit's binary_logloss: 0.00335736\tval's binary_logloss: 0.00767572\n",
      "[1600]\tfit's binary_logloss: 0.00322371\tval's binary_logloss: 0.00764743\n",
      "[1700]\tfit's binary_logloss: 0.00309895\tval's binary_logloss: 0.0076253\n",
      "[1800]\tfit's binary_logloss: 0.00298117\tval's binary_logloss: 0.00760411\n",
      "[1900]\tfit's binary_logloss: 0.00287209\tval's binary_logloss: 0.00758628\n",
      "[2000]\tfit's binary_logloss: 0.00276917\tval's binary_logloss: 0.00756805\n",
      "[2100]\tfit's binary_logloss: 0.00266768\tval's binary_logloss: 0.00755625\n",
      "[2200]\tfit's binary_logloss: 0.00256807\tval's binary_logloss: 0.00754852\n",
      "[2300]\tfit's binary_logloss: 0.00247876\tval's binary_logloss: 0.0075431\n",
      "Early stopping, best iteration is:\n",
      "[2305]\tfit's binary_logloss: 0.00247377\tval's binary_logloss: 0.00754219\n",
      "\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[100]\tfit's binary_logloss: 0.0102381\tval's binary_logloss: 0.0114147\n",
      "[200]\tfit's binary_logloss: 0.0078179\tval's binary_logloss: 0.00943833\n",
      "[300]\tfit's binary_logloss: 0.0066816\tval's binary_logloss: 0.00873916\n",
      "[400]\tfit's binary_logloss: 0.00599495\tval's binary_logloss: 0.0084155\n",
      "[500]\tfit's binary_logloss: 0.00551167\tval's binary_logloss: 0.00821936\n",
      "[600]\tfit's binary_logloss: 0.00515387\tval's binary_logloss: 0.00810981\n",
      "[700]\tfit's binary_logloss: 0.00485429\tval's binary_logloss: 0.00802253\n",
      "[800]\tfit's binary_logloss: 0.00462195\tval's binary_logloss: 0.00795759\n",
      "[900]\tfit's binary_logloss: 0.00441102\tval's binary_logloss: 0.00790056\n",
      "[1000]\tfit's binary_logloss: 0.00421761\tval's binary_logloss: 0.007847\n",
      "[1100]\tfit's binary_logloss: 0.00402708\tval's binary_logloss: 0.00780197\n",
      "[1200]\tfit's binary_logloss: 0.0038535\tval's binary_logloss: 0.00776779\n",
      "[1300]\tfit's binary_logloss: 0.00370278\tval's binary_logloss: 0.00773652\n",
      "[1400]\tfit's binary_logloss: 0.00354554\tval's binary_logloss: 0.00770044\n",
      "[1500]\tfit's binary_logloss: 0.00340619\tval's binary_logloss: 0.00767541\n",
      "[1600]\tfit's binary_logloss: 0.00327858\tval's binary_logloss: 0.00765078\n",
      "[1700]\tfit's binary_logloss: 0.00315807\tval's binary_logloss: 0.00762922\n",
      "[1800]\tfit's binary_logloss: 0.00304163\tval's binary_logloss: 0.00761153\n",
      "[1900]\tfit's binary_logloss: 0.00292504\tval's binary_logloss: 0.007588\n",
      "[2000]\tfit's binary_logloss: 0.00281614\tval's binary_logloss: 0.0075736\n",
      "[2100]\tfit's binary_logloss: 0.00271359\tval's binary_logloss: 0.00756064\n",
      "[2200]\tfit's binary_logloss: 0.00261704\tval's binary_logloss: 0.00754875\n",
      "[2300]\tfit's binary_logloss: 0.00252383\tval's binary_logloss: 0.00753619\n",
      "[2400]\tfit's binary_logloss: 0.00244053\tval's binary_logloss: 0.00752656\n",
      "[2500]\tfit's binary_logloss: 0.00235907\tval's binary_logloss: 0.00751598\n",
      "[2600]\tfit's binary_logloss: 0.00227724\tval's binary_logloss: 0.0075078\n",
      "[2700]\tfit's binary_logloss: 0.00219872\tval's binary_logloss: 0.00750067\n",
      "Early stopping, best iteration is:\n",
      "[2766]\tfit's binary_logloss: 0.00215101\tval's binary_logloss: 0.00749456\n",
      "\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[100]\tfit's binary_logloss: 0.0104746\tval's binary_logloss: 0.0107427\n",
      "[200]\tfit's binary_logloss: 0.00806635\tval's binary_logloss: 0.0088154\n",
      "[300]\tfit's binary_logloss: 0.00690699\tval's binary_logloss: 0.0081033\n",
      "[400]\tfit's binary_logloss: 0.00620998\tval's binary_logloss: 0.00774984\n",
      "[500]\tfit's binary_logloss: 0.00571487\tval's binary_logloss: 0.00755027\n",
      "[600]\tfit's binary_logloss: 0.00534283\tval's binary_logloss: 0.00741217\n",
      "[700]\tfit's binary_logloss: 0.00504787\tval's binary_logloss: 0.0073167\n",
      "[800]\tfit's binary_logloss: 0.00478879\tval's binary_logloss: 0.00724658\n",
      "[900]\tfit's binary_logloss: 0.00457146\tval's binary_logloss: 0.00718867\n",
      "[1000]\tfit's binary_logloss: 0.00436708\tval's binary_logloss: 0.00713064\n",
      "[1100]\tfit's binary_logloss: 0.00418242\tval's binary_logloss: 0.0070822\n",
      "[1200]\tfit's binary_logloss: 0.00401547\tval's binary_logloss: 0.00704242\n",
      "[1300]\tfit's binary_logloss: 0.00385924\tval's binary_logloss: 0.00700822\n",
      "[1400]\tfit's binary_logloss: 0.00371197\tval's binary_logloss: 0.00697647\n",
      "[1500]\tfit's binary_logloss: 0.00356892\tval's binary_logloss: 0.00695361\n",
      "[1600]\tfit's binary_logloss: 0.0034367\tval's binary_logloss: 0.00692221\n",
      "[1700]\tfit's binary_logloss: 0.00329986\tval's binary_logloss: 0.0069022\n",
      "[1800]\tfit's binary_logloss: 0.00317346\tval's binary_logloss: 0.00688566\n",
      "[1900]\tfit's binary_logloss: 0.0030508\tval's binary_logloss: 0.00686056\n",
      "[2000]\tfit's binary_logloss: 0.00293717\tval's binary_logloss: 0.00683972\n",
      "[2100]\tfit's binary_logloss: 0.00283031\tval's binary_logloss: 0.00682846\n",
      "[2200]\tfit's binary_logloss: 0.00272914\tval's binary_logloss: 0.00681516\n",
      "[2300]\tfit's binary_logloss: 0.00263647\tval's binary_logloss: 0.00680337\n",
      "[2400]\tfit's binary_logloss: 0.00254408\tval's binary_logloss: 0.00679201\n",
      "Early stopping, best iteration is:\n",
      "[2459]\tfit's binary_logloss: 0.00249446\tval's binary_logloss: 0.00678741\n",
      "\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[100]\tfit's binary_logloss: 0.0102319\tval's binary_logloss: 0.011255\n",
      "[200]\tfit's binary_logloss: 0.00787459\tval's binary_logloss: 0.00911496\n",
      "[300]\tfit's binary_logloss: 0.00676678\tval's binary_logloss: 0.00834495\n",
      "[400]\tfit's binary_logloss: 0.00605423\tval's binary_logloss: 0.00795739\n",
      "[500]\tfit's binary_logloss: 0.00554111\tval's binary_logloss: 0.00773346\n",
      "[600]\tfit's binary_logloss: 0.0051842\tval's binary_logloss: 0.00760478\n",
      "[700]\tfit's binary_logloss: 0.00489617\tval's binary_logloss: 0.00751199\n",
      "[800]\tfit's binary_logloss: 0.00466029\tval's binary_logloss: 0.00745097\n",
      "[900]\tfit's binary_logloss: 0.00444955\tval's binary_logloss: 0.00740143\n",
      "[1000]\tfit's binary_logloss: 0.00426915\tval's binary_logloss: 0.00735595\n",
      "[1100]\tfit's binary_logloss: 0.0040885\tval's binary_logloss: 0.00730852\n",
      "[1200]\tfit's binary_logloss: 0.00392109\tval's binary_logloss: 0.00727272\n",
      "[1300]\tfit's binary_logloss: 0.00376029\tval's binary_logloss: 0.00723821\n",
      "[1400]\tfit's binary_logloss: 0.00360524\tval's binary_logloss: 0.00720991\n",
      "[1500]\tfit's binary_logloss: 0.0034589\tval's binary_logloss: 0.00718576\n",
      "[1600]\tfit's binary_logloss: 0.00332426\tval's binary_logloss: 0.00716218\n",
      "[1700]\tfit's binary_logloss: 0.0032013\tval's binary_logloss: 0.00714116\n",
      "[1800]\tfit's binary_logloss: 0.00308625\tval's binary_logloss: 0.00711938\n",
      "[1900]\tfit's binary_logloss: 0.00297451\tval's binary_logloss: 0.00710493\n",
      "[2000]\tfit's binary_logloss: 0.00287233\tval's binary_logloss: 0.00709612\n",
      "[2100]\tfit's binary_logloss: 0.00277103\tval's binary_logloss: 0.00708426\n",
      "[2200]\tfit's binary_logloss: 0.00266857\tval's binary_logloss: 0.00707032\n",
      "[2300]\tfit's binary_logloss: 0.00257362\tval's binary_logloss: 0.00706187\n",
      "[2400]\tfit's binary_logloss: 0.00248408\tval's binary_logloss: 0.00705576\n",
      "Early stopping, best iteration is:\n",
      "[2399]\tfit's binary_logloss: 0.00248465\tval's binary_logloss: 0.00705573\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False     0.9987    0.9996    0.9991   1683412\n",
      "        True     0.9084    0.7537    0.8239      8899\n",
      "\n",
      "    accuracy                         0.9983   1692311\n",
      "   macro avg     0.9536    0.8766    0.9115   1692311\n",
      "weighted avg     0.9982    0.9983    0.9982   1692311\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import lightgbm\n",
    "from sklearn import metrics\n",
    "from sklearn import model_selection\n",
    "from sklearn import utils\n",
    "\n",
    "model = lightgbm.LGBMClassifier(\n",
    "    scale_pos_weight=2,\n",
    "    num_leaves=2 ** 6,\n",
    "    learning_rate=.01,\n",
    "    metric='binary',\n",
    "    random_state=42,\n",
    "    min_child_samples=30,\n",
    "    n_estimators=10_000\n",
    ")\n",
    "\n",
    "cv = model_selection.GroupKFold(n_splits=5)\n",
    "groups = X_train.index.get_level_values('sequence')\n",
    "\n",
    "oof = pd.Series(dtype=bool, index=X_train.index)\n",
    "if X_test is not None:\n",
    "    y_test = pd.DataFrame(index=X_test.index)\n",
    "\n",
    "for i, (fit_idx, val_idx) in enumerate(cv.split(X_train, y_train, groups=groups)):\n",
    "    \n",
    "    X_fit = X_train.iloc[fit_idx]\n",
    "    y_fit = y_train.iloc[fit_idx]\n",
    "    X_val = X_train.iloc[val_idx]\n",
    "    y_val = y_train.iloc[val_idx]\n",
    "    \n",
    "    model.fit(\n",
    "        X_fit, y_fit,\n",
    "        eval_set=[(X_fit, y_fit), (X_val, y_val)],\n",
    "        eval_names=['fit', 'val'],\n",
    "        early_stopping_rounds=20,\n",
    "        verbose=100\n",
    "    )\n",
    "    oof.iloc[val_idx] = model.predict(X_val)\n",
    "    \n",
    "    if X_test is not None:\n",
    "        y_test[i] = model.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    print()\n",
    "\n",
    "print(metrics.classification_report(y_train, oof, digits=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "precision    recall  f1-score   support\n",
    "\n",
    "       False     0.9987    0.9996    0.9991   1683412\n",
    "        True     0.9084    0.7537    0.8239      8899\n",
    "\n",
    "    accuracy                         0.9983   1692311\n",
    "   macro avg     0.9536    0.8766    0.9115   1692311\n",
    "weighted avg     0.9982    0.9983    0.9982   1692311"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature importances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7x7_skew        16226\n",
       "3x3_std         15515\n",
       "7x7_kurtosis    14378\n",
       "pixel_value     13211\n",
       "7x7_entropy     12990\n",
       "7x7_std         12600\n",
       "5x5_entropy     11923\n",
       "5x5_std         10648\n",
       "eccentricity     8375\n",
       "area             8329\n",
       "3x3_min          7552\n",
       "5x5_min          6739\n",
       "solidity         5105\n",
       "3x3_max          4495\n",
       "5x5_max          3051\n",
       "dtype: int32"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(model.feature_importances_, index=X_train.columns).sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Out-of-fold predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run toolbox.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sequence  frame  r    c  \n",
       "17        5      152  623    False\n",
       "506       4      253  440    False\n",
       "866       1      162  226    False\n",
       "238       3      88   432    False\n",
       "516       1      401  92     False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oof.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1280/1280 [00:02<00:00, 510.05it/s]\n"
     ]
    }
   ],
   "source": [
    "save_predictions(oof[oof].sort_index(), path='oof.json', n_sequences=1280)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.276092, (MSE: 44956.294525)\n"
     ]
    }
   ],
   "source": [
    "!python validation.py oof.json data/spotGEO/train_anno.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Score: 0.276092, (MSE: 44956.294525)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sequence</th>\n",
       "      <th>frame</th>\n",
       "      <th>r</th>\n",
       "      <th>c</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">1</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">1</th>\n",
       "      <th>2</th>\n",
       "      <th>334</th>\n",
       "      <td>0.000298</td>\n",
       "      <td>0.000424</td>\n",
       "      <td>0.000567</td>\n",
       "      <td>0.000758</td>\n",
       "      <td>0.000713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <th>339</th>\n",
       "      <td>0.000080</td>\n",
       "      <td>0.000072</td>\n",
       "      <td>0.000063</td>\n",
       "      <td>0.000129</td>\n",
       "      <td>0.000108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <th>264</th>\n",
       "      <td>0.000244</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>0.000192</td>\n",
       "      <td>0.000126</td>\n",
       "      <td>0.000172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <th>321</th>\n",
       "      <td>0.000535</td>\n",
       "      <td>0.000689</td>\n",
       "      <td>0.000592</td>\n",
       "      <td>0.000541</td>\n",
       "      <td>0.001030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <th>40</th>\n",
       "      <td>0.000227</td>\n",
       "      <td>0.000070</td>\n",
       "      <td>0.000190</td>\n",
       "      <td>0.000145</td>\n",
       "      <td>0.000179</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              0         1         2         3         4\n",
       "sequence frame r  c                                                    \n",
       "1        1     2  334  0.000298  0.000424  0.000567  0.000758  0.000713\n",
       "               7  339  0.000080  0.000072  0.000063  0.000129  0.000108\n",
       "               10 264  0.000244  0.000069  0.000192  0.000126  0.000172\n",
       "               6  321  0.000535  0.000689  0.000592  0.000541  0.001030\n",
       "               18 40   0.000227  0.000070  0.000190  0.000145  0.000179"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5120/5120 [00:10<00:00, 475.08it/s]\n"
     ]
    }
   ],
   "source": [
    "import zipfile\n",
    "\n",
    "sightings = y_test.mean(axis='columns') > .5\n",
    "save_predictions(sightings[sightings], path='submission.json', n_sequences=5120)\n",
    "\n",
    "with zipfile.ZipFile('submission.zip', mode='w') as f:\n",
    "    f.write('submission.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next is [PostProcessing.ipynb](PostProcessing.ipynb)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
